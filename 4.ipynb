{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Census dataset\n",
    "data = pd.read_csv(\"census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "\n",
    "# Encode the 'income_raw' data to numerical values\n",
    "income = income_raw.map({\n",
    "    '<=50K': '0',\n",
    "    '>50K': '1'\n",
    "})\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9320           32.81s\n",
      "         2           0.8442           32.07s\n",
      "         3           0.7910           32.57s\n",
      "         4           0.7557           32.92s\n",
      "         5           0.7304           32.16s\n",
      "         6           0.7091           31.56s\n",
      "         7           0.6939           31.24s\n",
      "         8           0.6780           30.72s\n",
      "         9           0.6673           30.68s\n",
      "        10           0.6593           30.37s\n",
      "        20           0.6119           29.38s\n",
      "        30           0.5930           28.88s\n",
      "        40           0.5828           28.33s\n",
      "        50           0.5722           27.75s\n",
      "        60           0.5645           27.12s\n",
      "        70           0.5578           26.51s\n",
      "        80           0.5532           26.04s\n",
      "        90           0.5491           25.46s\n",
      "       100           0.5458           24.90s\n",
      "       200           0.5229           19.81s\n",
      "       300           0.5072           14.85s\n",
      "       400           0.4961            9.89s\n",
      "       500           0.4863            4.95s\n",
      "       600           0.4779            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.871420674405749"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=600, learning_rate=0.3, random_state=0, verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9091           18.42s\n",
      "         2           0.8115           18.08s\n",
      "         3           0.7509           17.96s\n",
      "         4           0.7123           17.29s\n",
      "         5           0.6834           16.88s\n",
      "         6           0.6643           16.59s\n",
      "         7           0.6492           16.47s\n",
      "         8           0.6371           16.30s\n",
      "         9           0.6282           16.18s\n",
      "        10           0.6214           15.96s\n",
      "        20           0.5762           15.18s\n",
      "        30           0.5552           14.29s\n",
      "        40           0.5452           13.28s\n",
      "        50           0.5380           12.42s\n",
      "        60           0.5313           11.54s\n",
      "        70           0.5244           10.69s\n",
      "        80           0.5182            9.89s\n",
      "        90           0.5151            9.03s\n",
      "       100           0.5096            8.20s\n",
      "       200           0.4762            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8698728579325594"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "    n_estimators=200, \n",
    "    learning_rate=0.3, \n",
    "    random_state=0,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=25,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695411829740188"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.3, verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8182            5.72s\n",
      "         2           0.7381            5.39s\n",
      "         3           0.6944            5.40s\n",
      "         4           0.6769            5.29s\n",
      "         5           0.6549            5.37s\n",
      "         6           0.6435            5.24s\n",
      "         7           0.6336            5.14s\n",
      "         8           0.6292            5.02s\n",
      "         9           0.6225            4.97s\n",
      "        10           0.6168            4.91s\n",
      "        20           0.5799            4.27s\n",
      "        30           0.5657            3.69s\n",
      "        40           0.5529            3.12s\n",
      "        50           0.5472            2.59s\n",
      "        60           0.5417            2.06s\n",
      "        70           0.5367            1.55s\n",
      "        80           0.5331            1.03s\n",
      "        90           0.5290            0.52s\n",
      "       100           0.5243            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688778330569376"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.6, verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8857            5.66s\n",
      "         2           0.7966            5.52s\n",
      "         3           0.7479            5.31s\n",
      "         4           0.7143            5.31s\n",
      "         5           0.6956            5.32s\n",
      "         6           0.6767            5.21s\n",
      "         7           0.6653            5.12s\n",
      "         8           0.6535            5.08s\n",
      "         9           0.6449            5.01s\n",
      "        10           0.6373            4.96s\n",
      "        20           0.6031            4.17s\n",
      "        30           0.5826            3.61s\n",
      "        40           0.5735            3.08s\n",
      "        50           0.5635            2.56s\n",
      "        60           0.5573            2.04s\n",
      "        70           0.5516            1.52s\n",
      "        80           0.5484            1.01s\n",
      "        90           0.5428            0.51s\n",
      "       100           0.5378            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8700939745715865"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.4, verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8857           11.63s\n",
      "         2           0.7966           10.94s\n",
      "         3           0.7479           10.69s\n",
      "         4           0.7143           10.74s\n",
      "         5           0.6956           10.94s\n",
      "         6           0.6767           10.73s\n",
      "         7           0.6653           10.66s\n",
      "         8           0.6535           10.74s\n",
      "         9           0.6449           10.63s\n",
      "        10           0.6373           10.49s\n",
      "        20           0.6031            9.49s\n",
      "        30           0.5826            8.87s\n",
      "        40           0.5735            8.26s\n",
      "        50           0.5635            7.74s\n",
      "        60           0.5573            7.19s\n",
      "        70           0.5516            6.65s\n",
      "        80           0.5484            6.12s\n",
      "        90           0.5428            5.59s\n",
      "       100           0.5378            5.08s\n",
      "       200           0.5112            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.871199557766722"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.4, verbose=1, n_estimators=200)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8857           23.06s\n",
      "         2           0.7966           21.91s\n",
      "         3           0.7479           21.90s\n",
      "         4           0.7143           22.02s\n",
      "         5           0.6956           22.02s\n",
      "         6           0.6767           21.75s\n",
      "         7           0.6653           21.57s\n",
      "         8           0.6535           21.55s\n",
      "         9           0.6449           21.45s\n",
      "        10           0.6373           21.41s\n",
      "        20           0.6031           20.08s\n",
      "        30           0.5826           19.29s\n",
      "        40           0.5735           18.67s\n",
      "        50           0.5635           18.17s\n",
      "        60           0.5573           17.55s\n",
      "        70           0.5516           16.99s\n",
      "        80           0.5484           16.45s\n",
      "        90           0.5428           15.94s\n",
      "       100           0.5378           15.39s\n",
      "       200           0.5112           10.10s\n",
      "       300           0.4949            5.02s\n",
      "       400           0.4824            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8689883913764511"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.4, verbose=1, n_estimators=400)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8857           17.26s\n",
      "         2           0.7966           16.44s\n",
      "         3           0.7479           16.09s\n",
      "         4           0.7143           16.25s\n",
      "         5           0.6956           16.49s\n",
      "         6           0.6767           16.32s\n",
      "         7           0.6653           16.05s\n",
      "         8           0.6535           15.85s\n",
      "         9           0.6449           15.71s\n",
      "        10           0.6373           15.52s\n",
      "        20           0.6031           14.44s\n",
      "        30           0.5826           13.71s\n",
      "        40           0.5735           13.22s\n",
      "        50           0.5635           12.72s\n",
      "        60           0.5573           12.22s\n",
      "        70           0.5516           11.67s\n",
      "        80           0.5484           11.13s\n",
      "        90           0.5428           10.60s\n",
      "       100           0.5378           10.08s\n",
      "       200           0.5112            5.00s\n",
      "       300           0.4949            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8692095080154781"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.4, verbose=1, n_estimators=300)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8658           11.02s\n",
      "         2           0.7786           10.65s\n",
      "         3           0.7323           10.63s\n",
      "         4           0.7062           10.48s\n",
      "         5           0.6804           10.60s\n",
      "         6           0.6657           10.48s\n",
      "         7           0.6514           10.42s\n",
      "         8           0.6402           10.33s\n",
      "         9           0.6322           10.32s\n",
      "        10           0.6274           10.21s\n",
      "        20           0.5965            9.47s\n",
      "        30           0.5774            8.75s\n",
      "        40           0.5675            8.16s\n",
      "        50           0.5583            7.59s\n",
      "        60           0.5511            7.04s\n",
      "        70           0.5454            6.57s\n",
      "        80           0.5413            6.05s\n",
      "        90           0.5369            5.53s\n",
      "       100           0.5342            5.02s\n",
      "       200           0.5083            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8702045328911"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.45, verbose=1, n_estimators=200)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8658           12.50s\n",
      "         2           0.7786           11.96s\n",
      "         3           0.7323           11.78s\n",
      "         4           0.7062           11.66s\n",
      "         5           0.6804           11.72s\n",
      "         6           0.6657           11.57s\n",
      "         7           0.6514           11.54s\n",
      "         8           0.6402           11.45s\n",
      "         9           0.6323           11.46s\n",
      "        10           0.6275           11.31s\n",
      "        20           0.5965           10.48s\n",
      "        30           0.5797            9.82s\n",
      "        40           0.5638            9.25s\n",
      "        50           0.5569            8.68s\n",
      "        60           0.5514            8.12s\n",
      "        70           0.5464            7.60s\n",
      "        80           0.5420            7.08s\n",
      "        90           0.5389            6.55s\n",
      "       100           0.5354            6.03s\n",
      "       200           0.5100            1.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8706467661691543"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "    learning_rate=0.45, \n",
    "    verbose=1, \n",
    "    n_estimators=220,\n",
    "    min_samples_split=20\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8658           12.72s\n",
      "         2           0.7786           12.11s\n",
      "         3           0.7323           12.89s\n",
      "         4           0.7062           12.78s\n",
      "         5           0.6804           12.48s\n",
      "         6           0.6657           12.21s\n",
      "         7           0.6514           12.06s\n",
      "         8           0.6402           11.89s\n",
      "         9           0.6323           11.83s\n",
      "        10           0.6275           11.71s\n",
      "        20           0.5965           10.75s\n",
      "        30           0.5797            9.99s\n",
      "        40           0.5639            9.35s\n",
      "        50           0.5567            8.74s\n",
      "        60           0.5522            8.17s\n",
      "        70           0.5473            7.65s\n",
      "        80           0.5432            7.12s\n",
      "        90           0.5393            6.60s\n",
      "       100           0.5370            6.07s\n",
      "       200           0.5118            1.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8704256495301271"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "    learning_rate=0.45, \n",
    "    verbose=1, \n",
    "    n_estimators=220,\n",
    "    min_samples_split=30\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8658           12.77s\n",
      "         2           0.7786           12.23s\n",
      "         3           0.7324           12.01s\n",
      "         4           0.7064           11.91s\n",
      "         5           0.6806           11.91s\n",
      "         6           0.6659           11.76s\n",
      "         7           0.6516           11.67s\n",
      "         8           0.6398           11.54s\n",
      "         9           0.6315           11.56s\n",
      "        10           0.6244           11.53s\n",
      "        20           0.5900           10.59s\n",
      "        30           0.5769            9.82s\n",
      "        40           0.5687            9.32s\n",
      "        50           0.5594            8.76s\n",
      "        60           0.5560            8.20s\n",
      "        70           0.5498            7.67s\n",
      "        80           0.5477            7.13s\n",
      "        90           0.5440            6.62s\n",
      "       100           0.5410            6.09s\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "    learning_rate=0.45, \n",
    "    verbose=1, \n",
    "    n_estimators=220,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=20\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
